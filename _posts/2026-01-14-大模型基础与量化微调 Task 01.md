---
layout: post
title: "大模型基础与量化微调 Task 01"
date: 2026-01-14
category: "技术杂谈"
---

# 大模型基础与量化微调 | 202601 Blog
以下是关于Task 01 的一些思考

## *Base-LLM* 教程 思考
1. “无监督神经网络——自编码器” 这句话启发我联想到在科研里的Unet也是类似的结构，之前习惯叫做Encoder-Decoder架构，但是都只是用于重建，其输入是“好图+差图”，却没想到本身是可以作为一个**无监督**。更直接的例子是，稚晖君去年的一篇论文中，为了充分利用现实中的网络视频资源，其训练了一个自编码器，通过课程中描述的方式去捕捉视频中的动作特征，即是Latent embedding，用于VLM 的训练，那篇公众号文章称之为 *利用了网络中的海量资源* 。

# Citation and ...
### 课程&上述图片来源：  
[Base-LLM](https://datawhalechina.github.io/base-llm)
### 所属队伍：🐳DataWhale2026
#### 正在期末周，后续再补心得


